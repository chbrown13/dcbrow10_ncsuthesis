\chapter{BACKGROUND}
\label{chap-bg}

\begin{center}
%\begin{quote}
\textit{``I think the most interesting topic for software engineering research in the next ten years is, \\\textbf{`How do we get working programmers to actually adopt better practices?'}}''\footnote{\url{https://twitter.com/gvwilson/status/1142245508464795649?s=20}}
%\end{quote}
\end{center}

\section{Developer Behavior}


 \textit{Developer behavior} refers to the wide array of practices designed to help software engineers complete tasks while developing and maintaining software applications. Software engineering researchers have analyzed countless developer behaviors and show these activities provide many benefits to development teams. An example of a beneficial behavior is utilizing development tools to automatically complete programming tasks. The IEEE Software Engineering Body of Knowledge (SWEBOK), a suite of widely accepted software engineering practices and standards, suggests adopting development tools is a ``good practice'' that can ``enhance the chances of success over a wide range of project''~\citep[p.~A-4]{SWEBOK}. For example, using static analysis tools, or systems that automatically examine code to detect errors without running the program, is a behavior useful for improving code quality~\cite{GoogleFixit}, preventing errors~\cite{bessey2010few}, decreasing debugging time~\cite{Williams2007FaultFixTime}, lowering development costs~\cite{GouesGenProg}, and reducing developer effort~\cite{singh2017staticreview}. 
 
 However, despite scientific evidence of their benefit, studies also show software engineers often avoid static analysis tools~\cite{Johnson2013Why}, sparingly fix bugs reported during automated static analysis~\cite{marcilio2019static}, and seek to ignore alert notifications from these systems~\cite{nasif2019challenges}. Software engineering researcher Greg Wilson argues this tendency for developers to ignore useful programming tools and practices, or what I refer to as the \textit{developer behavior adoption problem}, is the most important research topic in the field for the next ten years.$^1$ The goal of this research is to work towards a solutions to this problem by creating effective systems that make convincing recommendations to encourage working programmers to adopt better behaviors and practices.

\subsection{Developer Behavior Adoption Problem}

Software engineering literature suggests developers frequently ignore beneficial development practices in their work, even though research outlines their advantages and benefits. For example, in addition to ignoring static analysis tools, studies have explored challenges and reasons why developers in industry avoid adopting automated tools for security~\cite{Xiao2014Security}, debugging~\cite{Cao2010Debugging}, refactoring~\cite{Murphy-HillBarriersRefactoring}, documentation~\cite{Forward2002Documentation}, build automation~\cite{Akond2017BuildTools}, and continuous integration~\cite{hilton2017CI}. Furthermore, researchers have examined why developers fail to adopt additional useful programming behaviors such as secure coding practices~\cite{Meng18Secure}, adequate software testing~\cite{Whittaker00Testing}, agile development methodologies~\cite{nerur2005agile}, ethical programming guidelines~\cite{McNamaraSmithE2018ACM}, and more. 

Ultimately, the developer behavior adoption problem can be costly for software developers and users. For example, the National Institute of Standards and Technology reports \textit{debugging}, or the process of finding and removing errors in code, is the most expensive and time-consuming development activity using 50-75\% of total costs and 70-80\% of programmers' time~\cite{NIST}. Additionally, Tricentis reported software failures impacted 3.7 billion users and lost over \$1.7 trillion USD in 2017~\cite{SoftwareFailWatch}. Furthermore, poor developer decisions have increasing effects for society over the next ten years as we become more dependent upon technology. Philosophy professor John K. Davis argues societal problems caused by technology, such as fake news, election interference, and data privacy concerns, will worsen as the power of technology outpaces the wisdom of humans~\cite{Davis20Wisdom}. Thus, my research seeks to explore ways to help developers make wiser decisions and avoid these consequences by increasing the adoption of beneficial developer behaviors.

\subsubsection*{Disclaimer*}

There are many reasons developers make poor choices and avoid beneficial programming behaviors. Although the research presented in this dissertation primarily focuses on programmers, bad decision-making in software engineering is not solely the fault of developers. While \textit{developer inertia}, or the unwillingness of programmers to adjust their existing workflow to learn new tools and practices, prevents the adoption of valuable behaviors~\cite{Murphy-Hill2011PeerInteraction}, many other barriers also prevent the adoption of developer behaviors in industry. For example, as reliance on technology increases, so do the number and complexity of decisions developers make in their work. Cognitive issues, including \textit{decision fatigue} and \textit{choice overload}, where decision quality declines as humans make more decisions and are overwhelmed by the amount of choices, can impair the decision-making of developers and lead to poor behaviors, such as copy-and-paste programming~\cite{DecisionFatigue}.

Companies can also prevent the adoption of developer behaviors. For example, Xiao and colleagues found that a company's policies and standards, culture, and structure play a role in developers' adoption of security tools~\cite{Xiao2014Security}. Similarly, Nerur and colleagues suggest management and organizations can block development teams from migrating to agile methodologies~\cite{nerur2005agile}. Other barriers, such as mandated tools and processes~\cite{Murphy-Hill2015HowDoUsers}, time pressure and deadlines~\cite{CostelloDeadline84}, and globally distributed development teams~\cite{ebert2008managing}, inhibit developers from discovering and adopting beneficial programming tools and practices in industry. Additionally, researchers at Google found that non-technical work factors, such as enthusiasm, support from peers, and performance feedback, play the most important role in the productivity of software developers~\cite{Murphy-Hill2019Productivity}.

Furthermore, researchers and toolsmiths contribute to the developer behavior adoption problem. Tilley and colleagues suggest adoption should be the goal for research-off-the-shelf (ROTS) software~\cite{Tilley2003ROTS}. However, Norman argues research results and tools often fail to meet the needs of industry developers, leading to a growing \textit{research-practice gap}~\cite{norman2010research}. For instance, Johnson and colleagues found the main reasons developers avoid static analysis tools are the inability to understand results, difficult customization and integration, and distrust of tool output~\cite{Johnson2013Why}. Additionally, Wohlin et al. outline challenges integrating empirical software engineering research into industry, citing issues such as lack of trust, differing goals, and poor knowledge exchange and integration~\cite{wohlin2013empirical}. In this work, I explore the developer behavior adoption problem from the perspective of software engineers by using behavioral science concepts to answer the motivating research question: ``\textit{How do we get working programmers to actually adopt better practices?}''.$^1$

\section{Nudge Theory}

To encourage the adoption of useful developer behaviors, I explore incorporating concepts from \textit{nudge theory} to improve automated recommendations to developers. A nudge is defined as any factor ``that alters behavior in a predictable way without forbidding alternatives or significantly changing economic incentives''~\citep[p.~6]{nudge}. For example, placing healthier foods at the front of a high school cafeteria in a ``convenience line'' nudged students to increase consumption of fruits and vegetables~\cite{Hanks2012Lunchroom}. This example fits the definition of a nudge because students have the option to ignore the target behavior, in this case eating healthy, to select unhealthy foods and they do not receive a reward for deciding to choose healthier options. Nudges are also used to impact human behavior on a much larger scale, for example the United States, the UK, Denmark, and Italy have implemented nudge unit teams to improve the behavior and decision-making of citizens~\cite{DelBalzoNudging}. Using nudge theory to improve the behavior and decision-making of software engineers involves not providing incentives nor forcing developers to adopt useful tools and practices.

\subsection{Digital Nudges}

Digital nudging refers to using technology and user interface design elements to nudge user behaviors in digital choice environments~\cite{weinmann2016digitalnudging}. For example, the FitBit\footnote{\url{https://www.fitbit.com/}} smart watch nudges users to increase physical activity and adopt healthier lifestyle behaviors by monitoring exercise activity, providing feedback to users, and presenting data collected from friends and other users~\cite{weinmann2016digitalnudging}. Prior work has also explored using digital nudges online to improve human behaviors such as enhancing user privacy and security decisions~\cite{acquisti2017nudges}, increasing financial savings~\cite{madrian2001power}, influencing social media sharing practices~\cite{huang2018digital}, and reducing social media usage~\cite{purohit2020designing}. 

Mirsch and colleagues argue implementing digital nudges are ``easier, faster and cheaper'' and provide more functionality than regular nudges~\citep[p.~635]{mirsch2017digital}. Furthermore, as more decisions are being made online, Weinmann argues digital nudges are becoming increasingly important because the design of interfaces will ``always (either deliberately or accidentally) influences people's choices''~\citep[p.~433]{weinmann2016digitalnudging}. 
While the majority of prior work in digital nudges studies their impact on the decision-making and behavior of software users, there is limited work exploring how they influence software developers, who are frequently faced with decisions in their work in digital choice environments, such as whether or not to adopt developer behaviors. This research aims to use digital nudges to encourage developers to adopt better practices by introducing and evaluating \framework.

\subsection{Choice Architecture}
\label{back-choice}

Nudges and digital nudges are effective for improving human behavior is because of their ability to influence the context and environment surrounding decision-making, or \textit{choice architecture}~\cite{thaler2013choice}. Choice architecture suggests the way decisions are framed and presented impacts the choices humans make. For example, changing the location of fruits and vegetables makes the choice of whether or not to eat healthy easier for humans. Another instance of a choice architecture is the ``default rule'', which suggests most decision-makers will select the default options when making decisions and has been shown to be effective for improving human behavior. For instance, the Square mobile payment app\footnote{\url{https://squareup.com/us/en}} sets the default behavior for users to tip merchants or actively choose a ``no tipping'' option. By using the default rule to make tipping the primary action, Square merchants in total earned over \$70 million in tips in 2013.\footnote{\url{https://www.fastcompany.com/3022182/how-square-registers-ui-guilts-you-into-leaving-tips}} 

Thaler and Sunstein note ``nudges are everywhere'' because ``choice architecture, both good and bad, is pervasive and unavoidable...Choice architects can preserve freedom of choice while also nudging people in directions that will improve their lives''~\citep[p.~255]{nudge}. Johnson and colleagues introduce 11 practical tools for choice architecture to convince people to adopt target behaviors and make better decisions~\cite{johnson2012beyond}. The research presented in this dissertation introduces and evaluates \framework, a novel approach that incorporates this concept into automated recommendations to developers. I aim to show that using choice architecture to improve the design and presentation of developer behavior decisions to software engineers within the context of their work can encourage working programmers to adopt better practices.

\section{Scope of Work}

Throughout the rest of this dissertation, the term \textit{nudge} is used to describe automated notifications recommending beneficial developer behaviors to software engineers as digital nudges. The nudges studied and created in this work do not provide incentives for developers choosing to adopt behaviors and allow developers to ignore our recommendations and choose alternate actions. Moreover, while nudges can be applied to many different aspects of software engineering, such as the IDE design, programming languages, and physical workspaces, my research aims to discover if nudges can encourage developers to adopt useful software engineering practices when faced with decisions while completing real-world programming tasks. The primary developer decision-making environment used to examine nudges for this research is GitHub, a popular online code hosting site with over 31 million developers, 96 million repositories, and 1 billion of code contributions~\cite{Octoverse}.\footnote{\url{https://octoverse.github.com/}} To evaluate nudges and automated recommendations, I developed software robots, or \textit{bots}, to recommend beneficial developer behaviors on public open source repositories to GitHub users.

\section{Related Work}

\subsection{Making Recommendations to Developers}

This work builds upon prior research exploring methods for making recommendations to software engineers. For the purpose of this research, \textit{developer recommendations} refer to any means of making suggestions or conveying information to improve the behavior of software engineers. To increase adoption of useful developer behaviors, prior work has investigated a variety of developer recommendation methods to suggest tools and practices to software engineers.

\subsubsection{Peer Learning}

Learning from peers, or human-to-human recommendations between with developers, has been shown to be an effective method for increasing knowledge. Twidale posits \textit{over-the-shoulder learning}, or informal collaborative learning and help-giving sessions between colleagues, as an effective approach for learning during computer supported work~\cite{twidale2005over}. For example, Murphy-Hill et al. explored how software engineers learn about new development tools and found that \textit{peer interactions} were the most effective method for software engineers to discover development tools compared to other technical methods~\cite{Murphy-Hill2015HowDoUsers}. Likewise, research shows \textit{peer debriefings}, or discussions between developers, are effective for improving code comprehension~\cite{Maalej2014CodeComprehension} and \textit{coworker recommendations} are the most popular method for spreading knowledge and increasing security tool adoption~\cite{Xiao2014Security}. 

Another form of over-the-shoulder learning in software engineering is \textit{pair programming}, or two developers working together to write code at the same machine. Cockburn and Williams found one of the benefits of this practice is learning from coworkers~\cite{Cockburn01Pair}. Similarly, Begel and Nagappan found developers at Microsoft reported that the spreading of code understanding and learning from partners were some of the main advantages of pair programming~\cite{begel08pair}. \textit{Peer code reviews}, where programmers critique code contributions before integrating them into source code, provide further opportunities for developers to learn from each other. For example, research shows programmers find peer code reviews beneficial for finding defects and improving code in addition to learning and knowledge transfer between developers~\cite{bacchelli2013expectations}. Furthermore, Cohen and colleagues argue \textit{over-the-shoulder reviews} are the most common type of peer code review in practice, and suggest these reviews ``lend themselves to learning and sharing between developers''~\citep[p.~27]{cohen2006best}.

While peer learning is effective for making recommendations and presenting knowledge to developers, studies show opportunities for these human-to-human interactions are declining. For example, Murphy-Hill and colleagues found peer interactions are the most effective mode of tool discovery, they also found these in-person recommendations occur infrequently in practice~\cite{Murphy-Hill2011PeerInteraction}. Additionally, Herbsleb argues the increase of global software engineering and distributed development teams limits changes for peer learning and causes less frequent and less effective communication between developers due to different time zones, cultural differences, and geographic distance~\cite{herbsleb2007global}. Another factor is the increase in remote work among software engineers. Turkle argues that as humans increasingly work and collaborate in isolated environments, technology will replace face-to-face communications~\cite{turkle2017alone}. Thus, it is necessary to explore technical approaches to make recommendations for developer behaviors.

\subsubsection{Online Programming Communities}

In-person human-to-human recommendations are in decline, however prior work has also explored the impact of online programming communities, or socio-technical websites dedicated to sharing knowledge and information specifically to programmers. In general, research shows online communities are beneficial for knowledge sharing across geographic locations and positional status~\cite{Hwang15online}. As opposed to over the shoulder learning through human-to-human recommendations, online programming communities support learning from peers through many-to-many and many-to-one recommendations~\cite{jensun17manyone}. Software engineering researchers have explored recommendations and developer learning in online programming communities. For example, Stack Overflow is a popular online question and answer site where developers can receive answers to their questions or respond to queries on many different programming topics. Research suggests comments on Stack Overflow posts are valuable for learning due to their ability to provide improvements and explanations~\cite{sengupta2020SOcomments}.

Additionally, researchers have explored the impact of online programming communities on recommendations to developers through social media. For example, prior work argues that social media has changed the way developers learn and share information GitHub~\cite{begel2010social}. Specifically, Singer et al. analyzed Twitter and found the popular social media platform is beneficial for increasing awareness and knowledge of development practices~\cite{singer2014twitter}. Aniche and colleagues also examined \textit{modern news aggregators} about software development, such as Hacker News and r/programming on Reddit, and found the purpose of most posts on these platforms are geared towards learning. Additionally, they found that receiving knowledge to apply different perspectives to existing work and making recommendations are the primary motivation for developers to post and respond to posts in these communities~\cite{Aniche18NewsAggregators}. 

Furthermore, prior work has explored recommendations to developers on code collaboration websites such as GitHub. For instance, research shows that badges on GitHub repositories are beneficial for improving the behavior of developers in terms of the quality of projects~\cite{dabbish2012social}, GitHub Discussions are valuable for learning between users~\cite{hata2021github}, and pull requests provide opportunities for programmers to learn from looking at other developers' code~\cite{Kalliamvakou15OSSCollaborative}. While online programming communities are useful for providing information and making recommendations to developers, these platforms are \textit{passive help systems}, or resources that require users to explicitly seek help. Prior work suggests these manual help-seeking systems are ineffective for making recommendations~\cite{Fischer1984ActiveHelpSystems}.

\subsubsection{Other Passive Approaches}

Previous research has explored a variety of other methods for making recommendations to software engineers. For example, prior work has also proposed continuous social screencasting~\cite{Murphy-HillScreencastingDiscovery} and live-coding~\cite{blackwell2014collaboration} as a mechanisms for developers to learn from peers virtually. Likewise, researchers have explored using \textit{crowdsourcing} to provide recommendations to developers to recommend programming tasks~\cite{Mao15Crowd} and increase understanding of Java APIs~\cite{Peng19Crowd}. Prior work has also proposed using \textit{gamification} to encourage developers to adopt better tools and practices through various methods such as \textsl{Blaze}, a system that uses points and leaderboards to improve programmer behavior~\cite{Snipes2014Experiences}, \textsl{Free Hugs}, an environment where developers create alter egos that evolve as players adopt better practices~\cite{FreeHugs}, and analyzing development tool usage through Serious Game Design Assessment (SGDA) frameworks~\cite{barik2016game}. Additionally, Murphy-Hill and colleagues posit Testing on the Toilet as a method for recommending development tools to programmers through restroom advertising~\cite{Murphy-Hill2019Toilet}. 

However, similar to seeking help in online programming communities, these developer recommendation approaches are examples of passive help systems. Previous research by Fischer and colleagues argues \textit{active help systems} that can automatically make recommendations to users while completing tasks are more effective than manual and static methods for software users~\cite{Fischer1984ActiveHelpSystems}. As opportunities for peer learning decline and static recommendation methods remain insufficient, automated approaches are needed to make recommendations and convey information to developers. Thus, the primary focus of my research involves analyzing and developing active help systems to recommend developer behaviors to software engineers. In the next section, I present relevant work studying automated techniques for making developer recommendations.

\subsection{Recommendation Systems}

Recommender systems, or tools that automatically collects inputs and aggregates and presents desired outputs to those seeking recommendations, are useful for assisting users in making choices when faced with insufficient personal experience~\cite{resnick1997recommender}. Prior work suggests these active help systems are more valuable for making recommendations to humans than passive systems. For example, Schafer and colleagues show that Automatic recommendations are more effective than Manual recommendations in e-commerce websites to suggest products to customers~\cite{schafer1999recommender}. Research has explored the concept of recommender systems for generating recommendations to software users. For example, automated systems have been used to recommend entertainment content on Netflix~\cite{Netflix}. 

Prior work offers tools and algorithms to generate a variety of recommendations to users. For example, Amazon implemented \textit{item-to-item collaborative filtering} to recommend products to customers~\cite{Amazon}, Yahoo! employs a \textit{contextual-bandit} approach to recommend personalized news articles~\cite{Yahoo}, OWL uses \textit{organization-wide learning} to log user commands to recommend tools Microsoft Word~\cite{OWL}, the Lumi\`ere Project uses \textit{Bayesian network models} to predict the goals and needs of software users~\cite{HorvitzLumiere}, and YouTube uses a \textit{batch-oriented pre-computation} algorithm to recommend videos to users on the world's most popular online video community~\cite{YouTube}. The research presented in this dissertation aims to study recommender systems focused on delivering recommendations to improve the behavior and decision-making of software engineers.

\subsubsection{Recommendation Systems for Software Engineering}

Recommendations systems for software engineering (RSSEs) are active help systems designed to assist and guide the actions of developers while completing programming tasks~\cite{RSSE}. RSSEs are made up of three components: 1) a data collection mechanism; 2) a recommendation engine to analyze input and generate recommendations; and 3) a user interface to present recommendations. For example, Hipikat observes the current state of source code to recommend software development artifacts, such as Bugzilla issue reports, to developers via an Eclipse IDE plugin~\cite{Hipikat}. Software engineering researchers and toolsmiths have created and evaluated a variety of RSSEs to help developers complete a wide range of programming tasks. For example, Spyglass~\cite{Spyglass}, Tricorder~\cite{Tricorder}, Prompter~\cite{Prompter}, and Dhruv~\cite{Dhruv} are automated systems developed to recommend code navigation techniques, program analysis behaviors, Stack Overflow posts, and bug report artifacts to software engineers. According to Gasparic and Janes, the majority of RSSEs recommend source code changes and coding artifacts to developers and the primary goals of most systems are to support a lack of knowledge among software engineers and overcome insufficient help from existing tools~\cite{Gasparic16RSSEReview}.

Similar to general recommender systems, RSSEs can be implemented with a variety of different methods to recommend developer behaviors through differing means. For example, Stench Spyglass~\cite{Spyglass} and Prompter~\cite{Prompter} provide information to developers within their development environment as Eclipse plugins whereas Dhruv presents recommendations in the OpenACS Bugtracker\footnote{https://www.project-open.com/en/package-bug-tracker}~\cite{Dhruv} and Tricorder is integrated into project builds at Google~\cite{Tricorder}. Additionally, previous research shows RSSEs are valuable for providing information to developers throughout the different phases of the software development processes~\cite{Pak2014RSSESDLC}. Prior work has also analyzed various recommendation algorithms in RSSEs, such as sorting by popularity, history-based recommendations, and collaborative filtering, to propose novel techniques~\cite{Murphy-Hill2012Fluency}. However, studies show developers often ignore recommendations from these systems. For example, prior work by Viriyakattiyaporn and Murphy suggests that the inability to make noticeable and timely recommendations led to ignored suggestions from Spyglass~\cite{viriyakattiyaporn2009challenges}. My research seeks to improve the effectiveness of recommendation systems for software engineering that refer to tools and systems designed to provide information to developers while developing and maintaining software.

In addition to creating automated recommender systems, research has explored ways to design effective recommendations. For instance, Fogg also outlines design principles for creating and designing persuasive technologies to encourage users to adopt target behaviors~\cite{Fogg2009Persuasive}. Generally, researchers have motivated the need to focus on user experiences and design in recommendation systems to encourage the adoption of target behaviors. For example, McNee and colleagues argue \textit{user-centric} recommendations focused on experiences and expectations are more important than the accuracy of recommender systems~\cite{McNee2006Accuracy}. Similarly, Konstan and Riedl suggest evaluating user experiences metrics is more important for automated recommender systems than optimizing recommendation algorithms~\cite{konstan2012recommender}. For RSSEs, Murphy and Murphy-Hill analyzed recommender systems for software development and found that \textit{trust} was more important than precision for software engineers, and conclude that ``trust trumps precision''~\cite{murphy2010trust} while Bavota and colleagues posit guidelines for designing systems to recommend code refactoring changes and argue the usability of refactoring recommendation systems is critical~\cite{Bavota2014RefactoringRSSE}.

While research suggests most RSSEs present results to users as lists~\cite{Gasparic16RSSEReview}, software engineering researchers have evaluated specific design decisions for improving automated developer recommendations. For example, prior work with Smith and Murphy-Hill found \textit{in-situ} design principles for a code navigation tool increased branchless navigation and was preferred by users~\cite{Flower}. Johnson and colleagues propose using developers' experiences to customize programming tools and environments with \textit{bespoke tools}~\cite{Johnson15Bespoke}. To study the initiation of system recommendations, Xiao et al. examined \textit{proactive} and \textit{reactive} user interface assistants and found that invocations not requiring user initiation were effective for applying and recalling commands~\cite{xiao2003quiet}. Furthermore, Robillard and colleagues present categories for design decisions to consider when developing RSSEs, including the context and input, recommendation engine and data source, and the output mode~\cite{RSSE}. My research proposes a new approach, \framework, to improve the design of recommender bots by integrating concepts from nudge theory in systems to improve the decision-making and behavior of developers.

\subsubsection{Recommender Bots}

Research has explored the use of software robots, or bots, to automatically make recommendations to users. For example, prior work has explored the usage of bots on social media platforms such as Twitter~\cite{Edwards14BotSocialMedia} and e-commerce websites~\cite{Reddy18BoteCommerce}. Prior work posits DevBots, or automated systems to support software development tasks~\cite{DevBots}. For example, David-DM\footnote{\url{https://david-dm.org/}} and Greenkeeper\footnote{\url{https://greenkeeper.io/}} are bots designed to recommend dependency updates for source code, Repairnator is a system that automatically fixes continuous integration build errors~\cite{Repairnator}, ReviewBot automates static analysis and recommends pull request reviewers during code reviews~\cite{ReviewBot}, and Mediam seeks to increase the adoption of analyses and techniques evaluated in software engineering research in industry~\cite{beschastnikh2017accelerating}. For the purposes of my research, I refer to DevBots created to automate tasks and convey information to software engineers as bots.

Bots have been highly adopted among software development teams. For example, research shows approximately a third the repositories on GitHub employ a type of bot on their project~\cite{wessel2018power}. However, prior work suggests recommendations from bots are insufficient for improving the behavior of developers. For example, Wessel and colleagues found that bots are useful for automating a variety of development tasks in open source software but also show software engineers reported facing many challenges interacting and comprehending feedback from these automated systems~\cite{wessel2018power}. Similarly, Erlenhov et al. discovered programmers find development bots inconvenient due to their interruption and noise, lack of trust, and poor usability~\cite{Erlenhov20EmpStudyBots} while Mirhosseini and Parnin found that developers were overwhelmed by bots generating automated pull requests on repositories~\cite{Samim2017AutoPullRequests}. Additionally, studies show developers exhibit more frustration through inappropriate language and negative emotions during interactions with chatbots~\cite{Hill2015Chatbots}, pull requests from bots take significantly longer to review than those submitted by humans~\cite{Wyrich21Waiting}, and systems emulating humans with human-presenting profiles are more effective than noticeable bot accounts~\cite{murgia16machines}. 

Prior work points to bot-human interactions as a primary factor in the reception of automated notifications. For example, the \textit{Principles of bot design} from Microsoft suggest that ``how \textit{smart} the bot is'' does not influence its success but delivering ``a great user experience'' does.\footnote{https://docs.microsoft.com/en-us/azure/bot-service/bot-service-design-principles?view=azure-bot-service-4.0} Similarly, Storey and Zagalsky note reducing interruptions, supporting context switching, and incorporating situational awareness into bots can improve the productivity of developers~\cite{storey2016bots}. Cerezo et al. also suggest \textit{user-driven communication} can improve the perception and adoption of recommendations from chatbots rather than using single-purpose bot-driven techniques~\cite{cerezo2019building}. My research aims to advance work in this field by utilizing interdisciplinary concepts to improve the design of automated recommendations from bots to increase their effectiveness for encouraging developers to adopt useful tools and behaviors.


\subsection{Interdisciplinary Methods for Improving Behavior}

Finally, my research applies concepts from behavioral science to improve the behavior and decision-making of software engineers. Prior work has similarly explored using interdisciplinary techniques to improve developer recommendations and learning. For example, Fleming and colleagues examined \textit{information foraging theory}, the study of how humans search for information, and apply relevant concepts to software engineering and how programmers seek information~\cite{fleming2013information}. Cao and et al. use Minimalist Learning Theory to develop \textit{Idea Garden}, an approach for integrating learning into programming environments and tasks to increase learning~\cite{cao2012ideagarden}. Furthermore, Singer explored integrating concepts from \textit{diffusion of innovations}, a sociology theory for explaining how knowledge and ideas spread, to increase tool adoption among software developers~\cite{Diffusion}. This work builds upon these studies to explore using behavioral science concepts to influence the behavior and decision-making of developers using nudge theory. 

To our knowledge, this was the first work to incorporate nudge theory and digital nudges to influence the behavior of software engineers. Prior research in this area has primarily focused on using digital nudges to influence the behavior of software users. For example, Acquisti and colleagues explored using digital nudges to improve user privacy and security decisions online~\cite{acquisti2017nudges}. Likewise, Huang and colleagues found that digitally nudging social media users impacted social sharing behavior~\cite{huang2018digital}. While these studies show that digital nudges are effective for influencing the behavior of software users, I explore using nudges to improve the behavior of software engineers. However, after introducing nudge theory as a solution to improve software engineer behavior and decision-making, recent work has explored using nudges to accelerate code reviews and encourage developers to review stale pull requests~\cite{maddila2020nudge}. In my work, I aim to use nudge theory to establish a framework for designing automated recommendations to improve the behavior and decision-making of programmers.